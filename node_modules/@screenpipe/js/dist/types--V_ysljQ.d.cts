/**
 * Types of content that can be queried in Screenpipe.
 */
type ContentType = "all" | "ocr" | "audio" | "ui" | "audio+ui" | "ocr+ui" | "audio+ocr";
/**
 * Parameters for querying Screenpipe.
 */
interface ScreenpipeQueryParams {
    /** Optional search query text */
    q?: string;
    /** Type of content to search for (default: "all") */
    contentType?: ContentType;
    /** Maximum number of results to return (default: 10) */
    limit?: number;
    /** Number of results to skip (for pagination) */
    offset?: number;
    /** Filter results after this ISO timestamp (e.g. "2023-01-01T00:00:00Z") */
    startTime?: string;
    /** Filter results before this ISO timestamp (e.g. "2023-01-01T00:00:00Z") */
    endTime?: string;
    /** Filter by application name (e.g. "chrome", "vscode") */
    appName?: string;
    /** Filter by window title */
    windowName?: string;
    /** Include base64-encoded screenshot frames in results */
    includeFrames?: boolean;
    /** Filter by minimum text length */
    minLength?: number;
    /** Filter by maximum text length */
    maxLength?: number;
    /** Filter by specific speaker IDs */
    speakerIds?: number[];
    /** Filter by frame name */
    frameName?: string;
    /** Filter by browser URL (for web content) */
    browserUrl?: string;
}
/**
 * Structure of OCR (Optical Character Recognition) content.
 */
interface OCRContent {
    frameId: number;
    text: string;
    timestamp: string;
    filePath: string;
    offsetIndex: number;
    appName: string;
    windowName: string;
    tags: string[];
    frame?: string;
    frameName?: string;
    browserUrl?: string;
    focused?: boolean;
}
/**
 * Structure of audio content.
 */
interface AudioContent {
    chunkId: number;
    transcription: string;
    timestamp: string;
    filePath: string;
    offsetIndex: number;
    tags: string[];
    deviceName: string;
    deviceType: string;
    speaker?: Speaker;
    startTime?: number;
    endTime?: number;
}
/**
 * Structure of UI content.
 */
interface UiContent {
    id: number;
    text: string;
    timestamp: string;
    appName: string;
    windowName: string;
    initialTraversalAt?: string;
    filePath: string;
    offsetIndex: number;
    frameName?: string;
    browserUrl?: string;
}
/**
 * Speaker information
 */
interface Speaker {
    id: number;
    name?: string;
    metadata?: string;
}
/**
 * Union type for different types of content items.
 */
type ContentItem = {
    type: "OCR";
    content: OCRContent;
} | {
    type: "Audio";
    content: AudioContent;
} | {
    type: "UI";
    content: UiContent;
};
/**
 * Pagination information for search results.
 */
interface PaginationInfo {
    limit: number;
    offset: number;
    total: number;
}
/**
 * Structure of the response from a Screenpipe query.
 */
interface ScreenpipeResponse {
    data: ContentItem[];
    pagination: PaginationInfo;
}
/**
 * Input control action types
 */
type InputAction = {
    type: "WriteText";
    data: string;
} | {
    type: "KeyPress";
    data: string;
} | {
    type: "MouseMove";
    data: {
        x: number;
        y: number;
    };
} | {
    type: "MouseClick";
    data: "left" | "right" | "middle";
};
/**
 * Response from input control operations
 */
interface InputControlResponse {
    success: boolean;
}
/**
 * Notification options
 */
interface NotificationOptions {
    title: string;
    body: string;
    actions?: NotificationAction[];
    timeout?: number;
    persistent?: boolean;
}
interface NotificationAction {
    id: string;
    label: string;
    callback?: () => Promise<void>;
}
/**
 * Inbox message structure
 */
interface InboxMessage {
    title: string;
    body: string;
    actions?: InboxMessageAction[];
}
interface InboxMessageAction {
    label: string;
    action: string;
    callback: () => Promise<void>;
}
interface ActionResponse {
    action: string;
}
/**
 * Settings types
 */
type AIProviderType = "native-ollama" | "openai" | "custom" | "embedded" | "screenpipe-cloud";
interface EmbeddedLLMConfig {
    enabled: boolean;
    model: string;
    port: number;
}
interface User {
    id?: string;
    email?: string;
    name?: string;
    image?: string;
    token?: string;
    clerk_id?: string;
    credits?: {
        amount: number;
    };
}
type AIPreset = {
    id: string;
    maxContextChars: number;
    url: string;
    model: string;
    defaultPreset: boolean;
    prompt: string;
} & ({
    provider: "openai";
    apiKey: string;
} | {
    provider: "native-ollama";
} | {
    provider: "screenpipe-cloud";
} | {
    provider: "custom";
    apiKey?: string;
});
interface Settings {
    openaiApiKey: string;
    deepgramApiKey: string;
    aiModel: string;
    aiUrl: string;
    customPrompt: string;
    port: number;
    dataDir: string;
    disableAudio: boolean;
    ignoredWindows: string[];
    includedWindows: string[];
    aiProviderType: AIProviderType;
    embeddedLLM: EmbeddedLLMConfig;
    enableFrameCache: boolean;
    enableUiMonitoring: boolean;
    aiMaxContextChars: number;
    analyticsEnabled: boolean;
    user: User;
    customSettings?: Record<string, any>;
    monitorIds: string[];
    audioDevices: string[];
    audioTranscriptionEngine: string;
    enableRealtimeAudioTranscription: boolean;
    realtimeAudioTranscriptionEngine: string;
    disableVision: boolean;
    aiPresets: AIPreset[];
}
/**
 * Pipe configuration types
 */
interface PipeConfig {
    [key: string]: any;
}
interface ParsedConfig<T = unknown> {
    fields: {
        name: string;
        value?: T;
        default?: T;
    }[];
}
interface TranscriptionChunk {
    transcription: string;
    timestamp: string;
    device: string;
    is_input: boolean;
    is_final: boolean;
    speaker?: string;
}
interface TranscriptionStreamResponse {
    id: string;
    object: string;
    created: number;
    model: string;
    choices: Array<{
        text: string;
        index: number;
        finish_reason: string | null;
    }>;
    metadata?: {
        timestamp: string;
        device: string;
        isInput: boolean;
        speaker?: string;
    };
}
interface VisionEvent {
    image?: string;
    text: string;
    timestamp: string;
    app_name?: string;
    window_name?: string;
    browser_url?: string;
}
interface VisionStreamResponse {
    type: string;
    data: VisionEvent;
}
interface EventStreamResponse {
    name: string;
    data: VisionEvent | TranscriptionChunk | any;
}
interface ElementSelector {
    app_name: string;
    window_name?: string;
    locator: string;
    use_background_apps?: boolean;
    activate_app?: boolean;
}
interface ElementPosition {
    x: number;
    y: number;
}
interface ElementSize {
    width: number;
    height: number;
}
interface ElementInfo {
    id?: string;
    role: string;
    label?: string;
    description?: string;
    text?: string;
    position?: ElementPosition;
    size?: ElementSize;
    properties: Record<string, any>;
}
interface ElementStats {
    total: number;
    definitely_interactable: number;
    sometimes_interactable: number;
    non_interactable: number;
    by_role: {
        [key: string]: number;
    };
}
interface FindElementsRequest {
    selector: ElementSelector;
    max_results?: number;
    max_depth?: number;
}
interface ClickElementRequest {
    selector: ElementSelector;
}
interface TypeTextRequest {
    selector: ElementSelector;
    text: string;
}

export type { AudioContent as A, ContentType as C, ElementSelector as E, FindElementsRequest as F, InputAction as I, NotificationOptions as N, OCRContent as O, PaginationInfo as P, Settings as S, TranscriptionChunk as T, UiContent as U, VisionEvent as V, ElementInfo as a, ElementStats as b, ElementPosition as c, ElementSize as d, ScreenpipeQueryParams as e, ScreenpipeResponse as f, Speaker as g, ContentItem as h, InputControlResponse as i, NotificationAction as j, InboxMessage as k, InboxMessageAction as l, ActionResponse as m, AIProviderType as n, EmbeddedLLMConfig as o, User as p, AIPreset as q, PipeConfig as r, ParsedConfig as s, TranscriptionStreamResponse as t, VisionStreamResponse as u, EventStreamResponse as v, ClickElementRequest as w, TypeTextRequest as x };
